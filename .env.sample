# =============================================================================
# Public Company Graph - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your credentials:
#   cp .env.sample .env
# =============================================================================

# -----------------------------------------------------------------------------
# Neo4j Database (REQUIRED)
# -----------------------------------------------------------------------------
# Connection URI - use neo4j:// for local, neo4j+s:// for Aura
NEO4J_URI=neo4j://localhost:7687

# Authentication
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password_here

# Database name (leave empty for default database)
# For Neo4j Aura, this is typically "neo4j"
NEO4J_DATABASE=domain

# -----------------------------------------------------------------------------
# OpenAI API (REQUIRED for embeddings)
# -----------------------------------------------------------------------------
# Get your API key at: https://platform.openai.com/api-keys
# Used for creating text embeddings from company descriptions
OPENAI_API_KEY=sk-proj-your_openai_key_here

# -----------------------------------------------------------------------------
# Datamule API (REQUIRED for 10-K download/parsing)
# -----------------------------------------------------------------------------
# Get your API key at: https://datamule.xyz
# Datamule is used to download and parse SEC 10-K filings
# See: https://github.com/john-googletv/datamule-python
DATAMULE_API_KEY=your_datamule_key_here

# -----------------------------------------------------------------------------
# Optional APIs
# -----------------------------------------------------------------------------
# Finnhub - Additional financial data (optional)
# Get your API key at: https://finnhub.io
FINNHUB_API_KEY=your_finnhub_key_here

# -----------------------------------------------------------------------------
# Notes
# -----------------------------------------------------------------------------
# - All REQUIRED keys must be set for the full pipeline to work
# - The pipeline uses a hybrid approach for 10-K parsing:
#   1. Primary: datamule library (works for ~88% of filings)
#   2. Fallback: Custom BeautifulSoup parser (catches remaining ~12%)
# - Embeddings are cached locally to minimize OpenAI API costs
# - Domain technology detection requires running domain_status separately
#   See: https://github.com/alexwoolford/domain_status
