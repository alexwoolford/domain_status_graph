# Cache Management Guide

## Overview

The parsing scripts use a diskcache-based cache to store expensive-to-compute results. This guide explains how to manage cache to ensure you're working with fresh data from your most recent parser runs.

## Cache Namespaces

Different scripts use different cache namespaces:

- **`10k_extracted`**: Parsed 10-K filing data (websites, business descriptions)
  - TTL: 365 days (long-lived, expensive to regenerate)
  - Used by: `parse_10k_filings.py`

- **`company_domains`**: Company domain data from multiple sources
  - TTL: 30 days
  - Used by: `collect_domains.py`

- **`embeddings`**: Vector embeddings for company/domain descriptions
  - TTL: Long-lived (expensive to regenerate)
  - Used by: `create_company_embeddings.py`

## Ensuring Fresh Parsed Data

### Option 1: Use `--force` Flag (Recommended)

The parser has a `--force` flag that forces re-parsing even if data is already cached:

```bash
# Force re-parse all files (overwrites existing cache)
python scripts/parse_10k_filings.py --execute --force
```

**When to use `--force`**:
- After modifying parser logic
- When you want to ensure all data is from the current run
- When debugging parsing issues
- When you suspect stale cache data

**What it does**:
- Skips cache lookup for all files
- Re-parses every file
- Overwrites existing cache entries with new results
- **Does NOT delete tar files or HTML files** (only updates cache)

### Option 2: Clear Cache Namespace

If you want to start completely fresh, clear the cache namespace:

```python
from domain_status_graph.cache import get_cache

cache = get_cache()
count = cache.clear_namespace("10k_extracted")
print(f"Cleared {count} entries from 10k_extracted namespace")
cache.close()
```

Or use the CLI command:
```bash
python -m domain_status_graph.cli cache clear --namespace 10k_extracted
```

### Option 3: Check Cache Statistics

Before parsing, check what's already cached:

```bash
python -m domain_status_graph.cli cache stats
```

This shows:
- Total cache entries
- Entries per namespace
- Cache size
- Cache directory location

## What Gets Deleted vs. What Doesn't

### ✅ NEVER Deleted (Protected)

These files are **NEVER** deleted by the parser:

1. **Tar files** (`data/10k_portfolios/`)
   - Required for high-quality parsing (86-93% success rate)
   - Expensive to re-download (~$4-5 for all companies)
   - Always kept, even with `--force`

2. **HTML files** (`data/10k_filings/`)
   - Extracted from tar files
   - Source data for parsing
   - Always kept, even with `--force`

### ⚠️ Can Be Cleared (Cache Only)

Only the **cache** can be cleared:

- **Cache entries** (`data/cache/`)
  - Stored parsed results (not source files)
  - Can be safely cleared and regenerated
  - Regenerated by re-running parser

## Workflow for Parser Iterations

When iterating on parser logic:

### Step 1: Clear Cache (Optional)
```bash
# Clear old cache to ensure fresh parsing
python -c "from domain_status_graph.cache import get_cache; c = get_cache(); c.clear_namespace('10k_extracted'); c.close(); print('Cache cleared')"
```

### Step 2: Parse with Force
```bash
# Force re-parse all files with new parser logic
python scripts/parse_10k_filings.py --execute --force
```

### Step 3: Verify Results
```bash
# Check what was parsed vs. cached
# The log will show: "Parsed: X, Cached: 0" (if cache was cleared)
```

## Cache Verification

### Check Cache Contents

```python
from domain_status_graph.cache import get_cache

cache = get_cache()

# List all keys in namespace
keys = cache.keys(namespace="10k_extracted", limit=10)
print(f"Sample keys: {keys}")

# Get a specific entry
data = cache.get("10k_extracted", "0000320193")  # Apple CIK
if data:
    print(f"Found cached data for Apple: {data.get('website', 'N/A')}")
else:
    print("No cached data found")

cache.close()
```

### Verify Freshness

The cache doesn't store timestamps by default, but you can verify freshness by:

1. **Checking log file timestamps**: Log files show when parsing occurred
2. **Using `--force`**: Forces fresh parsing regardless of cache
3. **Clearing cache before parsing**: Ensures all data is from current run

## Best Practices

1. **Use `--force` when iterating on parser logic**
   - Ensures you're testing with fresh data
   - Prevents confusion from stale cache

2. **Don't delete tar files or HTML files**
   - They're expensive/time-consuming to regenerate
   - Parser never deletes them anyway

3. **Clear cache namespace when needed**
   - Use when you want a completely fresh start
   - Safe to do - cache can be regenerated

4. **Check cache stats before parsing**
   - Understand what's already cached
   - Helps debug cache-related issues

5. **Use dry-run first**
   ```bash
   python scripts/parse_10k_filings.py  # Shows what would be parsed
   ```

## Troubleshooting

### "I'm seeing old results after changing parser logic"

**Solution**: Use `--force` flag:
```bash
python scripts/parse_10k_filings.py --execute --force
```

### "I want to start completely fresh"

**Solution**: Clear cache namespace first:
```bash
python -c "from domain_status_graph.cache import get_cache; c = get_cache(); c.clear_namespace('10k_extracted'); c.close()"
python scripts/parse_10k_filings.py --execute
```

### "How do I know if cache is being used?"

**Check the log output**:
- `Parsed: X` = Newly parsed (not from cache)
- `Cached: Y` = Used existing cache (skipped parsing)

### "Can I see what's in the cache?"

**Solution**: Use cache inspection:
```python
from domain_status_graph.cache import get_cache
cache = get_cache()
stats = cache.stats()
print(stats)  # Shows counts per namespace
cache.close()
```

## Related Documentation

- **Cache Files Explanation**: `docs/CACHE_FILES_EXPLANATION.md`
- **10-K Parsing**: `docs/10K_PARSING.md`
- **Cache Module**: `domain_status_graph/cache.py`
